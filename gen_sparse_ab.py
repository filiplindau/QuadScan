"""
Created 2020-04-03

Generate a sparse ab lookup data structure from a saved data file.
The input data is generated by MultiQuadLookup.generate_lookup

@author: Filip Lindau
"""

import time
import sys
import multiprocessing as mp
import numpy as np
from numpngw import write_png
import os
import json
from collections import namedtuple, OrderedDict
import pprint
import traceback
from scipy.signal import medfilt2d
from scipy.optimize import minimize, leastsq # Bounds, least_squares, BFGS, NonlinearConstraint
from scipy.sparse import csr_matrix, dok_matrix
#from scipy.optimize import lsq_linear
# from QuadScanTasks import TangoReadAttributeTask, TangoMonitorAttributeTask, TangoWriteAttributeTask, work_func_local2
from operator import attrgetter
from functools import reduce

#from tasks.GenericTasks import *
from QuadScanDataStructs import *


import logging

logger = logging.getLogger()
while len(logger.handlers):
    logger.removeHandler(logger.handlers[0])

f = logging.Formatter("%(asctime)s - %(module)s.   %(funcName)s - %(levelname)s - %(message)s")
fh = logging.StreamHandler()
fh.setFormatter(f)
logger.addHandler(fh)
logger.setLevel(logging.INFO)


def get_size(obj, seen=None):
    """Recursively finds size of objects"""
    size = sys.getsizeof(obj)
    if seen is None:
        seen = set()
    obj_id = id(obj)
    if obj_id in seen:
        return 0
    # Important mark as seen *before* entering recursion to gracefully handle
    # self-referential objects
    seen.add(obj_id)
    if isinstance(obj, dict):
        size += sum([get_size(v, seen) for v in obj.values()])
        size += sum([get_size(k, seen) for k in obj.keys()])
    elif hasattr(obj, '__dict__'):
        size += get_size(obj.__dict__, seen)
    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):
        size += sum([get_size(i, seen) for i in obj])
    return size


def generate_sparse_ab(data_filename="MS1_big.npz"):
    logger.info("Loading data...")
    npzfile = np.load(data_filename)
    A_lu = npzfile["A_lu"]
    k_lu = npzfile["k_lu"]
    logger.info("Loading complete. Starting binning")
    da = 0.2
    a_v = np.arange(-20, 20, da)
    db = 0.2
    b_v = np.arange(5, 7, db)
    A_dict = dict()
    d_a = np.digitize(A_lu[:, 0], a_v)
    d_b = np.digitize(A_lu[:, 1], b_v)
    for a_x in a_v:
        for b_x in b_v:
            logger.debug("a_x {0:.1f}, b_x {1:.1f}".format(a_x, b_x))
            a_ind = np.logical_and(A_lu[:, 0] > a_x - da / 2, A_lu[:, 0] < a_x + da / 2)
            b_ind = np.logical_and(A_lu[:, 1] > b_x - db / 2, A_lu[:, 1] < b_x + db / 2)
            ind = np.logical_and(a_ind, b_ind)
            a_y_p = A_lu[ind, 2]
            b_y_p = A_lu[ind, 3]
            k_tmp = k_lu[ind, :]
            y_dict_tmp = dict()
            for a_y in a_v:
                for b_y in b_v:
                    a_ind = np.logical_and(a_y_p > a_y - da / 2, a_y_p < a_y + da / 2)
                    b_ind = np.logical_and(b_y_p > b_y - db / 2, b_y_p < b_y + db / 2)
                    ind_y = np.logical_and(a_ind, b_ind)
                    k_good = k_tmp[ind_y, :]
                    if k_good.shape[0] > 0:
                        y_dict_tmp[(a_y, b_y)] = k_good
            if len(y_dict_tmp) > 0:
                A_dict[(a_x, b_x)] = y_dict_tmp
    return A_dict


def generate_sparse_ab2(A_lu=None, k_lu=None, data_filename="MS1_big.npz"):
    t0 = time.time()
    if A_lu is None:
        logger.info("Loading data...")
        npzfile = np.load(data_filename)
        A_lu = npzfile["A_lu"]
        k_lu = npzfile["k_lu"]
        logger.info("Loading complete.)")
    logger.info("Starting binning")
    da = 1.0
    a_v = np.arange(-20, 20, da)
    db = 1.0
    b_v = np.arange(-20, 20, db)
    A_dict = dict()
    d_a = np.digitize(A_lu[:, 0], a_v[:-1])
    # d_b = np.digitize(A_lu[:, 1], b_v)
    logger.info("Data digitized")
    nbins = a_v.shape[0]
    N = A_lu.shape[0]

    A_list = list()
    sign_m = np.array(np.meshgrid([0, 1], [0, 1], [0, 1], [0, 1])).reshape(4, -1).transpose()

    S_a = csr_matrix((A_lu[:, 0], [d_a, np.arange(N)]), shape=(nbins, N))
    logger.info("CSR matrix constructed")
    ind_a = [group for group in np.split(S_a.indices, S_a.indptr[1:-1])]

    def f_sign(x, k):
        ind = all((k >= 0) == x, axis=1)
        ki = k[ind, :]
        ki_ind = (ki**2).sum(1).argsort()[0:np.minimum(10, ki.shape[0])]
        return ki[ki_ind, :], ind.shape[0]

    def f_sign_old(x, k):
        return all((k >= 0) == x, axis=1)

    def f_len(x1, x2):
        if isinstance(x2, list):
            s = reduce(f_len, x2, 0)
        else:
            s = x2 + x1
        return s

    An_list = list()
    for j, ia in enumerate(ind_a):
        logger.info("Processing a={0:.2f}".format(a_v[j]))
        d_b = np.digitize(A_lu[ia, 1], b_v[:-1])
        nbins = b_v.shape[0]
        N = ia.shape[0]

        S_b = csr_matrix((A_lu[ia, 1], [d_b, np.arange(N)]), shape=(nbins, N))
        b_list = [k_lu[ia, :][group, :] for group in np.split(S_b.indices, S_b.indptr[1:-1])]
        k_list = list()
        n_list = list()
        # k_list = [np.apply_along_axis(f_sign, 1, sign_m, ka) for ka in b_list]
        for ik, ka in enumerate(b_list):
            # ks = np.apply_along_axis(f_sign, 1, sign_m, ka)
            nk = 0
            for l in range(sign_m.shape[0]):
                kl, nks = f_sign(sign_m[l, :], ka)
                k_list.append(kl)
                nk += nks
            # k_list.append([f_sign(sign_m[l, :], ka) for l in range(sign_m.shape[0])])
            n_list.append(nk)

        logger.info("Found {0} values".format(sum(n_list)))
        A_list.append(k_list)
        An_list.append(n_list)
    return A_list, An_list


def generate_sparse_ab3(A_lu=None, k_lu=None, data_filename="MS1_big.npz"):
    t0 = time.time()
    if A_lu is None:
        logger.info("Loading data...")
        npzfile = np.load(data_filename)
        A_lu = npzfile["A_lu"]
        k_lu = npzfile["k_lu"]
        logger.info("Loading complete.)")
    logger.info("Starting binning")
    da = 1.0
    a_v = np.arange(-15, 15, da)
    db = 1.0
    b_v = np.arange(-5, 25, db)
    A_dict = dict()
    d_a = np.digitize(A_lu[:, 0], a_v[:-1])
    # d_b = np.digitize(A_lu[:, 1], b_v)
    logger.info("Data digitized")
    nbins = a_v.shape[0]
    N = A_lu.shape[0]

    A_list = list()
    sign_m = np.array(np.meshgrid([0, 1], [0, 1], [0, 1], [0, 1])).reshape(4, -1).transpose()

    S_a = csr_matrix((A_lu[:, 0], [d_a, np.arange(N)]), shape=(nbins, N))
    logger.info("CSR matrix constructed")
    ind_a = [group for group in np.split(S_a.indices, S_a.indptr[1:-1])]

    def f_sign(x, k):
        ind = all((k >= 0) == x, axis=1)
        ki = k[ind, :]
        ki_ind = (ki**2).sum(1).argsort()[0:np.minimum(10, ki.shape[0])]
        return ki[ki_ind, :], ind.shape[0]

    def f_sign_old(x, k):
        return all((k >= 0) == x, axis=1)

    def f_len(x1, x2):
        if isinstance(x2, list):
            s = reduce(f_len, x2, 0)
        else:
            s = x2 + x1
        return s

    An_list = list()
    for j, ia in enumerate(ind_a):
        logger.info("Processing a={0:.2f}".format(a_v[j]))
        d_b = np.digitize(A_lu[ia, 1], b_v[:-1])
        nbins = b_v.shape[0]
        N = ia.shape[0]

        S_b = csr_matrix((A_lu[ia, 1], [d_b, np.arange(N)]), shape=(nbins, N))
        ind_b = [group for group in np.split(S_b.indices, S_b.indptr[1:-1])]

        for l, ib in enumerate(ind_b):
            nbins_a = a_v.shape[0]
            N_a = ib.shape[0]
            d_ay = np.digitize(A_lu[ia, 3][ib, :], a_v[:-1])
            S_ay = csr_matrix((A_lu[ia, 3][ib, :], [d_ay, np.arange(N)]), shape=(nbins, N))
        k_list = list()
        n_list = list()
        # k_list = [np.apply_along_axis(f_sign, 1, sign_m, ka) for ka in b_list]
        for ik, ka in enumerate(b_list):
            # ks = np.apply_along_axis(f_sign, 1, sign_m, ka)
            nk = 0
            for l in range(sign_m.shape[0]):
                kl, nks = f_sign(sign_m[l, :], ka)
                k_list.append(kl)
                nk += nks
            # k_list.append([f_sign(sign_m[l, :], ka) for l in range(sign_m.shape[0])])
            n_list.append(nk)

        logger.info("Found {0} values".format(sum(n_list)))
        A_list.append(k_list)
        An_list.append(n_list)
    return A_list, An_list


def generate_sparse_ab_set(A_lu=None, k_lu=None, data_filename="MS1_big.npz"):
    t0 = time.time()
    if A_lu is None:
        logger.info("Loading data...")
        npzfile = np.load(data_filename)
        A_lu = npzfile["A_lu"]
        k_lu = npzfile["k_lu"]
        logger.info("Loading complete.)")
    logger.info("Starting binning")
    A_list = list()
    sign_m = np.array(np.meshgrid([0, 1], [0, 1], [0, 1], [0, 1])).reshape(4, -1).transpose()

    da = 0.2
    a_v = np.arange(-15, 15, da)
    db = 0.2
    b_v = np.arange(-5, 25, db)
    A_dict = dict()
    d_a = np.digitize(A_lu[:, 0], a_v[:-1])
    d_b = np.digitize(A_lu[:, 1], b_v[:-1])
    logger.info("Data digitized")

    nbins_a = a_v.shape[0]
    N_a = A_lu.shape[0]
    S_a = csr_matrix((A_lu[:, 0], [d_a, np.arange(N_a)]), shape=(nbins_a, N_a))
    ind_a = [group for group in np.split(S_a.indices, S_a.indptr[1:-1])]
    logger.info("CSR a_x matrix constructed")
    S_ay = csr_matrix((A_lu[:, 2], [d_a, np.arange(N_a)]), shape=(nbins_a, N_a))
    ind_ay = [group for group in np.split(S_ay.indices, S_ay.indptr[1:-1])]
    logger.info("CSR a_y matrix constructed")

    nbins_b = b_v.shape[0]
    N_b = A_lu.shape[0]
    S_b = csr_matrix((A_lu[:, 1], [d_b, np.arange(N_b)]), shape=(nbins_b, N_b))
    ind_b = [group for group in np.split(S_b.indices, S_b.indptr[1:-1])]
    logger.info("CSR b_x matrix constructed")
    S_by = csr_matrix((A_lu[:, 3], [d_b, np.arange(N_b)]), shape=(nbins_b, N_b))
    ind_by = [group for group in np.split(S_by.indices, S_by.indptr[1:-1])]
    logger.info("CSR b_y matrix constructed")

    # ind_m = np.full((nbins_a, nbins_b, nbins_a, nbins_b), np.nan)
    ind_m = dict()
    k_m = dict()
    ka_m = dict()
    # for ia in np.arange(74, 75):
    for ia in range(len(a_v)):
        logger.info("ia {0}/{1}".format(ia, len(a_v)))
        for ib in range(len(b_v)):
            # logger.info("ia {0}/{1}       ib {2}/{3}".format(ia, len(a_v), ib, len(b_v)))
            ind_ab = np.intersect1d(ind_a[ia], ind_b[ib], assume_unique=True)
            if ind_ab.shape[0] > 0:
                # logger.info("{0} values".format(ind_ab.shape[0]))
                a_y_tmp = A_lu[ind_ab, 2]
                b_y_tmp = A_lu[ind_ab, 3]
                # a_v_y = np.linspace(a_y_tmp.min(), a_y_tmp.max(), 10)
                # a_v_y = np.arange(a_y_tmp.min(), a_y_tmp.max(), da)
                try:
                    ia_min = np.atleast_1d(a_v > a_y_tmp.min()).nonzero()[0][0]
                    ia_max = np.atleast_1d(a_v <= min(a_v[-1], a_y_tmp.max())).nonzero()[0][-1]
                    a_v_y = a_v[ia_min:ia_max]
                    # b_v_y = np.linspace(b_y_tmp.min(), b_y_tmp.max(), 10)
                    # b_v_y = np.arange(b_y_tmp.min(), b_y_tmp.max(), db)
                    ib_min = np.atleast_1d(b_v > b_y_tmp.min()).nonzero()[0][0]
                    ib_max = np.atleast_1d(b_v <= min(b_v[-1], b_y_tmp.max())).nonzero()[0][-1]
                except IndexError:
                    continue
                b_v_y = b_v[ib_min:ib_max]
                d_a_y = np.digitize(a_y_tmp, a_v_y[:-1])
                d_b_y = np.digitize(b_y_tmp, b_v_y[:-1])
                N_a_y = a_y_tmp.shape[0]
                nbins_a_y = a_v_y.shape[0]
                N_b_y = b_y_tmp.shape[0]
                nbins_b_y = b_v_y.shape[0]
                ind_y_tmp = dict()
                k_y_tmp = dict()
                ka_y_tmp = list()
                try:
                    S_ay = csr_matrix((a_y_tmp, [d_a_y, np.arange(N_a_y)]), shape=(nbins_a_y, N_a_y))
                    S_by = csr_matrix((b_y_tmp, [d_b_y, np.arange(N_b_y)]), shape=(nbins_b_y, N_b_y))
                    ind_ay = [group for group in np.split(S_ay.indices, S_ay.indptr[1:-1])]
                    ind_by = [group for group in np.split(S_by.indices, S_by.indptr[1:-1])]
                except ValueError as e:
                    # logger.info("ia {0}     ib {1}\n{2}".format(ia, ib, e))
                    continue

                for iay in range(len(a_v_y)):
                    for iby in range(len(b_v_y)):
                        # ind_abay = np.intersect1d(ind_ab, ind_ay[iay], assume_unique=True)
                        ind_aby = np.intersect1d(ind_ay[iay], ind_by[iby], assume_unique=True)
                        # logger.info("ab {0}, ay {1}, by {2}, abay {3}, aby {4}".format(ind_ab.shape[0],
                        #                                                                ind_ay[iay].shape[0],
                        #                                                                ind_by[iby].shape[0],
                        #                                                                ind_aby.shape[0]))
                        if ind_aby.shape[0] > 0:
                            # logger.info("Found {0}".format(ind_aby.shape[0]))
                            ind_y_tmp[iay + ia_min, iby + ib_min] = ind_aby[0]
                            k_y_tmp[iay + ia_min, iby + ib_min] = k_lu[ind_ab, :][ind_aby, :]
                            ka_y_tmp.append(k_lu[ind_ab, :][ind_aby[0], :])
                ind_m[ia, ib] = ind_y_tmp
                k_m[ia, ib] = k_y_tmp
                ka_m[ia, ib] = np.array(ka_y_tmp)

    return ind_m, k_m, ka_m


def binned_statistic(x, values, func, nbins, range):
    """The usage is nearly the same as scipy.stats.binned_statistic"""

    N = len(values)
    r0, r1 = range

    digitized = (float(nbins)/(r1 - r0)*(x - r0)).astype(int)
    S = csr_matrix((values, [digitized, np.arange(N)]), shape=(nbins, N))

    return [group for group in np.split(S.data, S.indptr[1:-1])]
